# 一、Java 内存模型的基础

## 1.并发编程模型的两个关键问题

在并发编程中，需要处理的两个关键问题：**线程之间如何通信及线程之间如何同步**。在命令式编程中，线程之间的通信机制有两种：**共享内存**和**消息传递**。

- 通信是指线程之间以何种机制来交换信息。
  - 在共享内存的并发模型中，线程之间共享程序的公共状态，通过**写-读内存**的公共状态进行**隐式**通信。
  - 在消息传递的并发模型中，线程之间没有公共状态，线程之间必须通过**发送消息**来**显式**进行通信。

- 同步是指程序中用于控制不同线程间操作发生相对顺序的机制。
  - 在共享内存并发模型中，同步是**显式**进行的。程序员必须显式指定某个方法或某段代码代码需要在线程之间互斥执行。
  - 在消息传递的并发模型中，由于消息的发送必须在消息的接收之前，因此同步是**隐式**进行的。

Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式的进行，整个通信过程对程序员完全透明。

## 2.Java 内存模型的抽象结构

在 Java 中，所有实例域、静态域和数组元素都存储在堆中，堆内存是线程共享的，本章中的“共享变量”就是指代实例域、静态域和数组元素。局部变量、方法定义参数和异常处理参数是线程私有的，不会有内存可见性问题，也不受内存模型的影响。

Java 线程之间的通信由 Java 内存模型（**JMM**）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度看：JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在**主内存（Main Memory）**中，每个线程都有一个私有的**本地内存（Local Memory）**，本地内存中存储了该线程以读/写共享变量的副本。*本地内存是一个抽象的概念，并不真实存在*。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。JMM 的抽象示意如图所示。

![image-20191228201620699](C:\Users\hncboy\AppData\Roaming\Typora\typora-user-images\image-20191228201620699.png)

从上图可知，线程 A 和线程 B 之间要通信的话，需要经历下面 2 个步骤。

1. 线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。
2. 线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。

通过下面的示意图来说明这两个步骤。

![image-20191228202611779](C:\Users\hncboy\AppData\Roaming\Typora\typora-user-images\image-20191228202611779.png)

从上图可知，本地内存 A 和本地内存 B 由主内存中共享变量 x 的副本。假设初始时，这三个内存中 x 的值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改的 x 的值刷新到主内存中，此时主内存中的 x 的值更新为了 1。然后线程 B 去主内存读取线程 A 更新后 x 的值，此时线程 B 本地内存中 x 的值也变为 1。

JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 Java 程序提供内存可见性保证。

## 3.从源代码到指令序列的重排序

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。

- 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- 指令级并行的重排序：现代处理器采用了指令级并行技术（Instruction Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器的执行顺序。
- 内存系统的重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

![image-20200201164449476](C:\Users\hncboy\AppData\Roaming\Typora\typora-user-images\image-20200201164449476.png)

其中 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器重排序，JMM 的编译器重排序规则会**禁止特定类型**的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 Java 编译器在生成指令时，插入特定类型的内存屏障指令，通知内存屏障指令来禁止特定类型的处理器重排序。

总的来说，JMM 会通知禁止特定类型的编译器重排序和处理器重排序来提供一致的内存可见性保证。

## 4.并发编程模型的分类

现代处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，避免由于处理器停顿下来等待向内存写入数据的而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区对同一内存地址的多次写，减少对内存总线的占用。由于每个处理器的写缓冲区仅对它所在的处理器可见，因此可能回导致处理器执行内存操作的顺序会与内存实际的操作执行顺序不一致（可能会写-读操作进行重排序）。

为了保证内存可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为 4 类。

| 屏障类型            | 指令示例                   | 说明                                                         |
| ------------------- | -------------------------- | ------------------------------------------------------------ |
| LoadLoad Barriers   | Load1; LoadLoad; Load2     | 确保 Load1 数组的装载在 Load2 及后续装载指令之前。           |
| StoreStore Barriers | Store1; StoreStore; Store2 | 确保 Store1 数据对其他处理器可见（将修改的变量刷新到主内存）先于 Store2 及所有后续存储指令的存储。 |
| LoadStore Barriers  | Load1; LoadStore; Store2   | 确保 Load1 数据装载先于 Store2 及所有后续的存储指令刷新到主内存。 |
| StoreLoad Barriers  | Store1; StoreLoad; Load2   | 确保 Store1 数据对其他处理器可见（将修改的变量刷新到主内存）先于 Load2 及所有后续装载指令的装载。 |

StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他 3 个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销大，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（StoreLoad Barriers 会使该屏障之前的所有内存访问指令，包括存储和装载指令完成之后，才执行该屏障之后的内存访问指令）。

## 5. happens-before 简介

从 JDK5 开始，使用新的 JSR-133 内存模型。JSR-133 使用 happens-before 的概念来阐述操作之间的内存可见性。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间要存在 happens-before 关系。

两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行。happens-before 仅要求前一个操作的执行结果对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

基本的 happens-before 规则如下：

- 程序顺序性规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。
- 监视器锁规则：对一个锁的解锁，happens-before 于随后对这个锁的加锁。
- volatile 规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。
- 传递性：如果 A happens-before B，且 B happens-before C，那么 A happens-before C。

一个 happens-before 规则对应于一个或多个编译器和处理器重排序规则。

![image-20200201185754511](C:\Users\hncboy\AppData\Roaming\Typora\typora-user-images\image-20200201185754511.png)

# 二、重排序

重排序是指编译器和处理器为了优化程序性能对指令序列进行重排序的一种手段。

## 1.数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖性可分为以下三种类型：

| 名称   | 代码示例           | 说明                         |
| ------ | ------------------ | ---------------------------- |
| 写后读 | a = 1;<br />b = a; | 先写一个变量，再读这个变量。 |
| 写后写 | a = 1;<br />a = 2; | 先写一个变量，再写这个变量。 |
| 读后写 | a = b;<br />b = 1; | 先读一个变量，再写这个变量。 |

编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。这里的数据依赖性只针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。

## 2.as-if-serial 语义

含义：不管怎么重排序（编译器和处理器为了提高并发速度），（单线程）程序的执行结果不能改变。编译器、runtime 和处理器都必须遵循 as-if-serial 语义。

如以下代码。

```java
int i = 1;      // A
int j = 2;      // B
int k = i * j;  // C
```

A 和 B 不存在依赖关系，A 和 B 可能会被编译器和处理器重排序，而 A 和 C 以及 B 和 C 之间存在数据依赖关系，因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 之前。而 A 和 B 不管怎么重排序，代码的执行结果都是一致的。

as-if-serial 语义把单线程程序保护了起来，使程序员无需担心重排序会干扰单线程程序的结果，也无需担心内存可见性问题。

## 3.程序顺序规则

根据 happens-before 的程序顺序规则，上述的示例代码存在 3 个 happens-before 关系。

- A happens-before B
- B happens-before C
- A happens-before C

第三个 happens-before 关系是根据 happens-before 规则的传递性推导的。

这里的 A happens-before B，但实际执行时 B 却可以在 A 之前执行。JMM 只要求前一个操作的执行结果对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里的操作 A 的执行结果不需要对操作 B 可见，而且重排序操作 A 和操作 B 的结果也一致。在这种情况下，JMM 会认为**这种重排序并不非法**，JMM 允许这种重排序。

## 4.重排序对多线程的影响

# 三、顺序一致性

## 1.数据竞争与顺序一致性

## 2.顺序一致性内存模型

## 3.同步程序的顺序一致性结果

## 4.未同步程序的执行特性

# 四、volatile 的内存语义



